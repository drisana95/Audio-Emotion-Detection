# Audio-Emotion-Detection

# Project Overview
The Audio Emotion Detection project is designed to classify emotions from audio files using machine learning techniques. This project leverages the TESS Toronto emotional speech set dataset for training and testing. The model uses MFCC (Mel-frequency cepstral coefficients) as features to represent the audio and a neural network built with TensorFlow/Keras to classify the emotions.
