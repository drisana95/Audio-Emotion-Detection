# Audio-Emotion-Detection

# Project Overview
The Audio Emotion Detection project is designed to classify emotions from audio files using machine learning techniques. This project leverages the TESS Toronto emotional speech set dataset for training and testing. The model uses MFCC (Mel-frequency cepstral coefficients) as features to represent the audio and a neural network built with TensorFlow/Keras to classify the emotions.

# Dataset
Name: TESS (Toronto Emotional Speech Set)
Format: .wav audio files
Structure: Organized into folders, where each folder represents a different emotion.

# Libraries
To use this project, you will need to have the following libraries installed:

librosa
seaborn
matplotlib
scikit-learn
pandas
IPython
numpy
keras

# Results
![image](https://github.com/user-attachments/assets/c3e12247-0768-4362-b3d2-258e4a962b2b)

The model achieves:

Training Accuracy: Over 95% after 50 epochs.
Validation Accuracy: Similar trends with slight fluctuations (as shown in the graph)

